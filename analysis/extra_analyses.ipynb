{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9855c69",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "77b6189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import ffmpeg\n",
    "import pprint\n",
    "import math\n",
    "import os\n",
    "from math import atan2, degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab368754",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "02e69c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/tcvs1l0j4ld27ynbn58_v9hh0000gn/T/ipykernel_91164/1694146236.py:2: DtypeWarning: Columns (1,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_1 = pd.read_csv('exps1-6_compiled_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# load compiled data from all experiments\n",
    "data_1 = pd.read_csv('exps1-6_compiled_data.csv')\n",
    "data_2 = pd.read_csv('exp7_compiled_data.csv')\n",
    "data_3 = pd.read_csv('exp8_compiled_data.csv')\n",
    "\n",
    "all_data = pd.concat([data_1, data_2, data_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e7c26",
   "metadata": {},
   "source": [
    "### Calculate the size of video stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "34f6b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The coded video stimulus size is 1050 x 1680\n",
      "The height:length ratio is 5:8\n",
      "\n",
      "The presentation size on the screen is a height of 500 pixels\n",
      "Given the ratio, that means 500 x 800 pixels in size\n",
      "\n",
      "The height in degrees visual angle is 13.296\n",
      "The length in degrees visual angle is 21.126\n"
     ]
    }
   ],
   "source": [
    "# load a random video from the stimulus sets\n",
    "probe  = ffmpeg.probe('/Users/kirstenziman/Desktop/Desktop/DIDEC_entire_corpus/analysis_3/subject_8/285896.bmp_pp92_L3_V1_veridical_freeview_isoFalse_fps144.mp4')\n",
    "video_streams = [stream for stream in probe[\"streams\"] if stream[\"codec_type\"] == \"video\"]\n",
    "width = video_streams[0]['coded_width']\n",
    "height = video_streams[0]['coded_height']\n",
    "\n",
    "# obtain the raw size of the video and the height:length ratio\n",
    "print ()\n",
    "print ('The coded video stimulus size is '+str(height)+' x '+str(width))\n",
    "print ('The height:length ratio is '+str(int(height/math.gcd(width, height)))+':'+str(int(length/math.gcd(width, height)))); print()\n",
    "\n",
    "# presentation size on the screen, given size ratio and height in pixels\n",
    "pixel_size = 500 # presentation height coded in experiment\n",
    "print ('The presentation size on the screen is a height of 500 pixels')\n",
    "print ('Given the ratio, that means '+str(pixel_size)+' x '+str(int((pixel_size/(height/math.gcd(width, height)))*length/math.gcd(width, height)))+' pixels in size')\n",
    "\n",
    "# given the specs of our monitor, calculate dimensions in centimeters\n",
    "# screen specs --> https://www.displayspecifications.com/en/model/31826fe\n",
    "\n",
    "# screen dimensions in pixels: 2560 x 1440\n",
    "# screen dimensions in centimeters: 59.6736 x 33.5664\n",
    "pixels_per_cm = 2560/59.6736\n",
    "height_cm = pixel_size / pixels_per_cm\n",
    "length_cm = 800 / pixels_per_cm\n",
    "\n",
    "# calculate degrees visual angle of video stimulus\n",
    "viewing_distance_cm = 50\n",
    "height_vis_angle = degrees(math.atan2((height_cm/2),viewing_distance_cm))\n",
    "length_vis_angle = degrees(math.atan2((length_cm/2),viewing_distance_cm))\n",
    "\n",
    "print()\n",
    "print('The height in degrees visual angle is '+str(round(height_vis_angle*2,3)))\n",
    "print('The length in degrees visual angle is '+str(round(length_vis_angle*2,3)))\n",
    "\n",
    "# for a review on calculating visual angle of a stimulus, see:\n",
    "# https://osdoc.cogsci.nl/2.9.1/miscellaneous/visual-angle/\n",
    "# https://en.wikipedia.org/wiki/Visual_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea58ed8",
   "metadata": {},
   "source": [
    "### Average experiment duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aa2be453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data['responses'] = all_data['responses'].fillna('b')\n",
    "# all_data[all_data['responses'].str.contains('Q0')]['trial_index']-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "974bca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/tcvs1l0j4ld27ynbn58_v9hh0000gn/T/ipykernel_91164/3270910561.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_dat['responses'] = sub_dat['responses'].fillna('nope')\n",
      "/var/folders/59/tcvs1l0j4ld27ynbn58_v9hh0000gn/T/ipykernel_91164/3270910561.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_dat['stimulus'] = sub_dat['stimulus'].fillna('nope')\n"
     ]
    }
   ],
   "source": [
    "# get times when subjects start reading instructions\n",
    "start_times = list(all_data[all_data['trial_index']==1]['time_elapsed'])\n",
    "\n",
    "# get times when subjects enter last response\n",
    "# note, different ending index for different experiments\n",
    "end_times = []\n",
    "\n",
    "for sub in all_data['ID'].unique():\n",
    "    \n",
    "    # for exps where subjects enter 'judgment' and 'confidence' (exps 1-6) \n",
    "    # get the timestamp of the last 'confidence' rating     \n",
    "    sub_dat  = all_data[all_data['ID']==sub]\n",
    "    sub_dat['responses'] = sub_dat['responses'].fillna('nope')\n",
    "    sub_dat['stimulus'] = sub_dat['stimulus'].fillna('nope')\n",
    "    \n",
    "    if sub_dat['version'].unique() in [\n",
    "       'Mismatched Image', \n",
    "       'Scrambled Order versus Veridical (Image)',\n",
    "       'Scrambled Order versus Veridical (Black)',\n",
    "       'Horizontal Flip versus Veridical (Black)',\n",
    "       'Reverse Order versus Veridical (Image)',\n",
    "       'Reverse Order versus Veridical (Black)']:\n",
    "            \n",
    "        sub_conf = sub_dat[sub_dat['responses'].str.contains('confidence')]\n",
    "        max_t = sub_conf.iloc[69]['time_elapsed'].item()\n",
    "\n",
    "    # for exps where subjects pressed a button (exp 7)\n",
    "    # get timestamp of last button press\n",
    "    elif sub_dat['version'].unique() in ['learning']:\n",
    "        sub_keys = sub_dat[sub_dat['stimulus'].str.contains('attention')]\n",
    "        max_t = sub_keys.iloc[69]['time_elapsed'].item()\n",
    "            \n",
    "    # for exps where subjects answer multiple questions (exp 8)\n",
    "    # get the timestamp of the last question response   \n",
    "    elif sub_dat['version'].unique() in ['Subjective Ratings Over Image']:\n",
    "        sub_post = sub_dat[sub_dat['responses'].str.contains('post-5')]\n",
    "        max_t = sub_post.iloc[69]['time_elapsed'].item()\n",
    "        \n",
    "    else:\n",
    "        print('Experiment not recognized')\n",
    "        \n",
    "    end_times.append(max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "79106320",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df = pd.DataFrame({'end_times':end_times,'start_times': start_times})\n",
    "timing_df['timing_diff'] = timing_df['end_times'] - timing_df['start_times']\n",
    "timing_df['timing_diff_minutes'] = timing_df['timing_diff']/60_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c6c0eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.125% of participants finished in under 30 minutes\n"
     ]
    }
   ],
   "source": [
    "percent_under_thirty = timing_df[timing_df['timing_diff_minutes']<30].shape[0] / timing_df.shape[0]\n",
    "print(str(percent_under_thirty*100)+'% of participants finished in under 30 minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc793f32",
   "metadata": {},
   "source": [
    "### Average frames per second in initial video stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4337cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate average number of video frames in non fps144 videos\n",
    "\n",
    "# stim_folders = ['/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_1/STIM_SET_1',\n",
    "#                '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_2/STIM_SET_2',\n",
    "#                 '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_3/STIM_SET_3',\n",
    "#                 '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_4/FOR_REV_BLOBBY_STIM',\n",
    "#                 '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_5/FOR_REV_MAP_BLOBBY_STIM',\n",
    "#                 '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_6/STIM_SET_5',\n",
    "#                ]\n",
    "\n",
    "# s = '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_7/experiments/'\n",
    "\n",
    "# for r in range(1,21):\n",
    "#     d = s+'STIM_SET_'+str(r)\n",
    "#     stim_folders.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a484d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in stim_folders:\n",
    "#     raw_vids = [x for x in os.listdir(folder) if 'mp4' in x and 'fps' not in x]\n",
    "    \n",
    "#     print(folder)\n",
    "#     print(len(raw_vids))\n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26da486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0216d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
