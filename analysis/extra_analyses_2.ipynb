{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2f67f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eee630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stimulus_helpers import *\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c9ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kirstenziman/Documents/predicting_attention/analysis/exp1-6_data/0dd6057w_SCRAMBLE_PILOT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2cc0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = list(df['image'].unique()[0::2][1:])\n",
    "\n",
    "subjects = [b.split('_')[3] for b in l]\n",
    "images   = [b.split('_')[2].split('/')[1] for b in l]\n",
    "lists    = [b.split('_')[4][1] for b in l]\n",
    "\n",
    "new_df = pd.DataFrame({'subject':subjects,'image':images,'list':lists,\n",
    "                      'sub_version':1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15327f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_maker_center_of_mass(fixations, dictionary, this_list, this_version, stim_type, isolated=False):\n",
    "    '''\n",
    "    INPUTS:\n",
    "\n",
    "    fixations  - pandas dataframe containing only fixation data from one subject viewing one image\n",
    "    dictionary - dictionary containing two keys, one with the image name and one with the fixaiton coordinates\n",
    "    stim_type  - string describing the type of attention stimulus to make: veridical / scrambled / mismatched / reversed\n",
    "    isolated   - boolean describing whether the attention will be isolated (True) or be overlaid on an image (False)\n",
    "\n",
    "    OUTPUTS:\n",
    "\n",
    "    technically, none\n",
    "\n",
    "    This will create and save two files:\n",
    "    - mp4 video of the attention video stimulus\n",
    "    - csv containing video metadata\n",
    "        - # of attention chunks (num_chunks)\n",
    "        - order of attention chunks (order)\n",
    "        - image filename (dictionary['image'])\n",
    "        - subject ID (dictionary['subject'])\n",
    "    '''\n",
    "\n",
    "    # This function can make veridical and scrambled attention spotlight videos, isolated or overlaid on an image\n",
    "\n",
    "    lengths = []; movie_frames = []; total_counter = 0; centers = []\n",
    "    order   = list(set(fixations))\n",
    "    num_chunks = len(order)\n",
    "\n",
    "    if len(order)>2:\n",
    "\n",
    "        # scramble order for scrambled stimulus\n",
    "        if stim_type=='scrambled':\n",
    "            while order == list(range(1, len(order)+1)):\n",
    "                remainder = order[1:]\n",
    "                np.random.shuffle(remainder)\n",
    "                new_list = [order[0]] + list(remainder)\n",
    "                order = new_list\n",
    "\n",
    "        # record how many chunks stay in the same place (besides the first one), if any\n",
    "        number_same = sum(x == y for x, y in zip(order, list(range(1, len(order)+1))))-1\n",
    "\n",
    "        # for each fixation chunk\n",
    "        for x in order:\n",
    "\n",
    "            length_counter = 0; tuple_list = []; total_list = []\n",
    "\n",
    "            # for first chunk, collect the largest and smallest x and y vals\n",
    "            if x==1:\n",
    "            \tx1_vals=[100000000000,0]; y1_vals=[100000000000,0]\n",
    "            \t# initialize very high and very low values, respectively\n",
    "\n",
    "            # for each item in fixie chunk list AND each tuple\n",
    "            for a,b in zip(fixations, dictionary['fixations']):\n",
    "\n",
    "                # if item from fixie chunk list is the number from first for statement:\n",
    "                if a == x:\n",
    "                    tuple_list.append(b)\n",
    "                    total_counter += 1\n",
    "                    total_list.append(total_counter)\n",
    "                    if x==1:\n",
    "                    \tx1_vals,y1_vals = first_bounds_update(x1_vals,y1_vals,b)\n",
    "\n",
    "            # determine if first hotspot contains center of screen\n",
    "            first_centered   = one_centered(x1_vals, y1_vals)\n",
    "            reverse_centered = one_centered(y1_vals, x1_vals)\n",
    "\n",
    "            # pass into plotting function\n",
    "            c_o_m = plot_heatmap({'image':dictionary['image'], 'fixations':tuple_list},\n",
    "                         filename='/Users/kirstenziman/Downloads/images_with_borders/Images_resized_greyborders/all/' + dictionary['image'],\n",
    "                         alpha=.6, cmap=\"Greys_r\", clean=False, isolated=isolated, other=None, l=this_list)\n",
    "\n",
    "            centers.append(c_o_m)\n",
    "\n",
    "            # save jpegs\n",
    "#             for q in total_list:\n",
    "#                 addin = get_addin(q)\n",
    "#                 plt.savefig(dictionary['image']+addin+str(q)+'.jpg')\n",
    "\n",
    "#         # determine frame rate given number of images\n",
    "#         framerate = get_framerate()\n",
    "\n",
    "#         if framerate!=0:\n",
    "#             ending = '_'+dictionary['subject'][0]+'_L'+str(this_list)+'_V'+str(this_version)+'_'+stim_type+'_freeview_iso'+str(isolated)\n",
    "\n",
    "#         # compile and save video\n",
    "#             (\n",
    "#             ffmpeg\n",
    "#             .input('*.jpg', pattern_type='glob', framerate=framerate)\n",
    "#             .output(dictionary['image']+ending+'.mp4')\n",
    "#             .run()\n",
    "#             )\n",
    "\n",
    "#             # remove leftover jpeg images\n",
    "#             remove_jpegs()\n",
    "\n",
    "#         else:\n",
    "#             print('framerate is zero for '+dictionary['image'])\n",
    "\n",
    "#             for file_name in os.listdir('.'):\n",
    "#                 if file_name.endswith('.jpg'):\n",
    "#                     os.remove(file_name)\n",
    "\n",
    "#         meta = pd.DataFrame({'image':dictionary['image'],'subject':dictionary['subject'],'num_chunks':num_chunks, 'order':[order], 'center_first':str(first_centered), 'center_first_reverse':str(reverse_centered), 'chunks_same': number_same, 'proportion_same':number_same/(len(order)-1), 'x1_vals':[x1_vals], 'y1_vals':[y1_vals]})\n",
    "\n",
    "#         meta.to_csv(dictionary['image']+ending+'.csv')\n",
    "\n",
    "    else:\n",
    "        print('len(k) <= 2: '+dictionary['image'])\n",
    "\n",
    "    return(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ae1ba11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('stim1_example.csv') \n",
    "counter = 0\n",
    "\n",
    "veridical_centers = []\n",
    "\n",
    "for idx,row in new_df.iterrows():\n",
    "    \n",
    "    free_view   = get_gaze(row['subject'],int(row['list']),int(row['sub_version']),row['image'])\n",
    "    free_fixies = get_fixies(free_view) \n",
    "    free_dicts  = make_the_dicts(free_view)\n",
    "\n",
    "    center_verid = movie_maker_center_of_mass(free_fixies, free_dicts, int(row['list']), row['sub_version'], 'veridical', isolated=False)\n",
    "    \n",
    "    veridical_centers.append(center_verid)\n",
    "    \n",
    "    counter +=1; print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3f150fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cents = veridical_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7ad81",
   "metadata": {},
   "source": [
    "Now, we want to make scrambled order from our scrambled stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5141b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/Users/kirstenziman/Desktop/predicting_attention/experiments/experiment_1/STIM_SET_1/'\n",
    "scrambled_meta = [pd.read_csv(p+'/'+x) for x in os.listdir(p)\n",
    "                 if 'scrambled_freeview_isoFalse.csv' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4603072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>subject</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>order</th>\n",
       "      <th>center_first</th>\n",
       "      <th>center_first_reverse</th>\n",
       "      <th>chunks_same</th>\n",
       "      <th>proportion_same</th>\n",
       "      <th>x1_vals</th>\n",
       "      <th>y1_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>713593.bmp</td>\n",
       "      <td>pp64</td>\n",
       "      <td>13</td>\n",
       "      <td>[1, 5, 11, 7, 4, 10, 6, 8, 12, 2, 9, 13, 3]</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>[816.0, 837.0]</td>\n",
       "      <td>[471.0, 498.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       image subject  num_chunks  \\\n",
       "0           0  713593.bmp    pp64          13   \n",
       "\n",
       "                                         order center_first  \\\n",
       "0  [1, 5, 11, 7, 4, 10, 6, 8, 12, 2, 9, 13, 3]            F   \n",
       "\n",
       "  center_first_reverse  chunks_same  proportion_same         x1_vals  \\\n",
       "0                    F            1         0.083333  [816.0, 837.0]   \n",
       "\n",
       "          y1_vals  \n",
       "0  [471.0, 498.0]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_meta_df = pd.concat(scrambled_meta)\n",
    "scr_meta_df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc8ed3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_listy = []\n",
    "\n",
    "for idx,x in new_df.iterrows():\n",
    "# for each image in the df\n",
    "\n",
    "    im = x['image']\n",
    "        \n",
    "    # get the corresponding image row in scr_meta_df\n",
    "    row = scr_meta_df[scr_meta_df['image'].str.contains(im)]\n",
    "    \n",
    "    # get the blob order for the stimulus\n",
    "    order = ast.literal_eval(row['order'].item())\n",
    "    \n",
    "    # take the veridical centers at that idx in the list\n",
    "    this_v = v_cents[idx]\n",
    "    \n",
    "    # make a new version in the order of the blob order \n",
    "    new_version = [0]*len(order)\n",
    "    \n",
    "    for idx,x in enumerate(order):\n",
    "        new_version[idx] = this_v[x-1]\n",
    "    \n",
    "    # append it to the scrambled listy\n",
    "    scrambled_listy.append(new_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1597273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cents = scrambled_listy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "938d6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cents\n",
    "v_dists = []\n",
    "\n",
    "for v in v_cents:\n",
    "    \n",
    "    dists = []\n",
    "\n",
    "    # for each pair of points in the centers list:\n",
    "    for idx,x in enumerate(v[:-1]):\n",
    "        distance = (((v[idx+1][0]-x[0])**2)+((v[idx+1][1]-x[1])**2))**.5\n",
    "        dists.append(distance)\n",
    "    v_dists.append(np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "414f0280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "9.747228003255456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "253.21673434952598"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(v_dists))\n",
    "print(scipy.stats.sem(v_dists))\n",
    "np.mean(v_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b2a551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cents\n",
    "s_dists = []\n",
    "\n",
    "for s in s_cents:\n",
    "    \n",
    "    dists = []\n",
    "\n",
    "    # for each pair of points in the centers list:\n",
    "    for idx,x in enumerate(s[:-1]):\n",
    "        distance = (((s[idx+1][0]-x[0])**2)+((s[idx+1][1]-x[1])**2))**.5\n",
    "        dists.append(distance)\n",
    "    s_dists.append(np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aae14d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "15.43323421970984\n",
      "\n",
      "370.1230248644132\n"
     ]
    }
   ],
   "source": [
    "print(len(s_dists))\n",
    "print(scipy.stats.sem(s_dists[:-6]))\n",
    "print()\n",
    "print(np.mean(s_dists[:-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7393a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.read_csv('stim_prop_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b04ac4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>image</th>\n",
       "      <th>list</th>\n",
       "      <th>sub_version</th>\n",
       "      <th>s_dist</th>\n",
       "      <th>v_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pp61</td>\n",
       "      <td>498155.bmp</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>494.341515</td>\n",
       "      <td>344.391746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pp100</td>\n",
       "      <td>1592581.bmp</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>474.922749</td>\n",
       "      <td>297.681562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pp71</td>\n",
       "      <td>1159572.bmp</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>412.653456</td>\n",
       "      <td>204.608818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject        image list  sub_version      s_dist      v_dist\n",
       "0    pp61   498155.bmp    2          1.0  494.341515  344.391746\n",
       "1   pp100  1592581.bmp    3          1.0  474.922749  297.681562\n",
       "2    pp71  1159572.bmp    1          1.0  412.653456  204.608818"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['s_dist'] = s_dists\n",
    "new_df['v_dist'] = v_dists\n",
    "\n",
    "new_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fd9573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct.head(n=3) #['unique_image_label'].str.split('/')#.str.split('_')\n",
    "correct['s_dist']=np.nan\n",
    "correct['v_dist']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad467d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=9.997249220985065, pvalue=4.719394880832063e-15, df=69)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_rel(new_df['s_dist'],new_df['v_dist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60ad4e",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e17878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,x in new_df.iterrows():\n",
    "    \n",
    "#     im = x['image']\n",
    "    \n",
    "#     s = x['s_dist']\n",
    "#     v = x['v_dist']\n",
    "    \n",
    "#     correct.loc[correct['unique_image_label'].str.contains(im),'s_dist'] = s\n",
    "#     correct.loc[correct['unique_image_label'].str.contains(im),'v_dist'] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e5789de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct['dist_diff'] = correct['s_dist'] - correct['v_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "346c1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.stats.ttest_rel(correct['s_dist'], correct['v_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3e409fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.histplot(s_dists)\n",
    "# sb.histplot(v_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b7c1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats.stats import pearsonr\n",
    "\n",
    "# pearsonr(correct['dist_diff'],correct['Percent correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d42dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.lmplot(x='dist_diff',y='Percent correct',data=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce883e63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# s_cents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c781af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y<=1050.00 and x<=1680.00:\n",
    "\n",
    "# center location\n",
    "\n",
    "# center_x = 1050/2\n",
    "# center_y = 1680/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b235bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average dist from center for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33f79178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_cents[0][0][0] - center_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f4c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ef96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_cent_dfs = []\n",
    "# datframe['half'] = np.nan\n",
    "\n",
    "\n",
    "# for idx,vvv in enumerate(v_cents):\n",
    "#     datframe = pd.DataFrame(vvv)\n",
    "#     # print(datframe.shape)\n",
    "#     datframe = datframe[1:]\n",
    "#     # print(datframe.shape)\n",
    "#     datframe['number'] = idx\n",
    "#     datframe['blob_number'] = range(1,datframe.shape[0]+1)\n",
    "    \n",
    "#     datframe['half'] = np.nan #datframe.shape[0]/2\n",
    "    \n",
    "#     if datframe.shape[0]%2 == 0:\n",
    "#         middle = datframe.shape[0]/2\n",
    "        \n",
    "#         datframe.loc[datframe['blob_number']<=middle,'half'] = 'first'\n",
    "#         datframe.loc[datframe['blob_number']> middle,'half'] = 'second'\n",
    "    \n",
    "#     else:\n",
    "#         middle_low = np.floor(datframe.shape[0]/2)\n",
    "#         middle_up  = np.ceil(datframe.shape[0]/2)\n",
    "        \n",
    "\n",
    "    \n",
    "#     v_cent_dfs.append(pd.DataFrame(datframe))\n",
    "    \n",
    "# vcd = pd.concat(v_cent_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59c83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vcd.groupby(['number','half']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb4dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_cent_dfs = []\n",
    "# datframe['half'] = np.nan\n",
    "\n",
    "# for idx,sss in enumerate(s_cents):\n",
    "#     datframe = pd.DataFrame(sss)\n",
    "#     # print(datframe.shape)\n",
    "#     datframe = datframe[1:]\n",
    "#     # print(datframe.shape)\n",
    "#     datframe['number'] = idx\n",
    "#     datframe['blob_number'] = range(1,datframe.shape[0]+1)\n",
    "    \n",
    "#     datframe['half'] = np.nan #datframe.shape[0]/2\n",
    "    \n",
    "#     if datframe.shape[0]%2 == 0:\n",
    "#         middle = datframe.shape[0]/2\n",
    "        \n",
    "#         datframe.loc[datframe['blob_number']<=middle,'half'] = 'first'\n",
    "#         datframe.loc[datframe['blob_number']> middle,'half'] = 'second'\n",
    "    \n",
    "#     else:\n",
    "#         middle_low = np.floor(datframe.shape[0]/2)\n",
    "#         middle_up  = np.ceil(datframe.shape[0]/2)\n",
    "        \n",
    "\n",
    "    \n",
    "#     s_cent_dfs.append(pd.DataFrame(datframe))\n",
    "    \n",
    "# scd = pd.concat(s_cent_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab415c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scd.groupby(['number','half']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "632c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_cents\n",
    "# s_dists = []\n",
    "\n",
    "# for s in s_cents:\n",
    "    \n",
    "#     dists = []\n",
    "\n",
    "#     # for each pair of points in the centers list:\n",
    "#     for idx,x in enumerate(s[:-1]):\n",
    "#         distance = (((s[idx+1][0]-x[0])**2)+((s[idx+1][1]-x[1])**2))**.5\n",
    "#         dists.append(distance)\n",
    "#     s_dists.append(np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4284ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(s_dists)\n",
    "# np.mean(s_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.ttest_rel(s_dists, v_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b0b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.sem(s_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d79fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.sem(v_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4186d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.std(s_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52868a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.std(v_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa106eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79b782e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndimage.measurements.center_of_mass(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "167708b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(free_dicts['fixations'])\n",
    "# df['chunk'] = free_fixies\n",
    "\n",
    "# array = np.array(df[df['chunk']==1][[0,1]])\n",
    "# array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a31fff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# len(free_fixies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6870432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free_fixies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('stim_prop_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e206b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances between blobs\n",
    "\n",
    "# d=√ ( (x_2-x_1)²+ (y_2-y_1)²)\n",
    "\n",
    "# dists = []\n",
    "\n",
    "# # for each pair of points in the centers list:\n",
    "# for idx,x in enumerate(centers[:-1]):\n",
    "#     distance = (((centers[idx+1][0]-x[0])**2)+((centers[idx+1][1]-x[1])**2))**.5\n",
    "#     dists.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fedf6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance = ((x[0]-centers[idx+1][0])**2)+((x[1]-centers[idx+1][1])**2)**.5\n",
    "# centers[idx+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38b2c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45212346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14537c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (((608-924)**2)+((513-328)**2))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04451d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stim 1 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91659cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('stim1_example.csv') \n",
    "# df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b548ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "\n",
    "# for idx,row in df.iterrows():\n",
    "    \n",
    "#     free_view   = get_gaze(row['subject'],int(row['list']),int(row['sub_version']),row['image'])\n",
    "#     free_fixies = get_fixies(free_view) \n",
    "#     free_dicts  = make_the_dicts(free_view)\n",
    "\n",
    "#     movie_maker(free_fixies, free_dicts, int(row['list']), row['sub_version'], 'scrambled', isolated=True)\n",
    "#     movie_maker(free_fixies, free_dicts, int(row['list']), row['sub_version'], 'veridical', isolated=True)\n",
    "    \n",
    "#     counter +=1; print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
